{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Yeast Dataset\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the Yeast dataset to understand the data structure, distributions, and relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Exploratory Data Analysis - Yeast Dataset\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import project modules\n",
    "from src.data_loader import load_yeast_data\n",
    "from src.config import *\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üîç Exploratory Data Analysis - Yeast Dataset\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Yeast Dataset...\n",
      "==============================\n",
      "Dataset shape: (1484, 9)\n",
      "Columns: ['mcg', 'gvh', 'alm', 'mit', 'erl', 'pox', 'vac', 'nuc', 'class']\n",
      "\n",
      "First 5 rows:\n",
      "             mcg   gvh   alm   mit  erl  pox   vac   nuc class\n",
      "ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22   MIT\n",
      "ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22   MIT\n",
      "ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22   MIT\n",
      "AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22   NUC\n",
      "AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22   MIT\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1484 entries, ADT1_YEAST to G6PD_YEAST\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mcg     1484 non-null   float64\n",
      " 1   gvh     1484 non-null   float64\n",
      " 2   alm     1484 non-null   float64\n",
      " 3   mit     1484 non-null   float64\n",
      " 4   erl     1484 non-null   float64\n",
      " 5   pox     1484 non-null   float64\n",
      " 6   vac     1484 non-null   float64\n",
      " 7   nuc     1484 non-null   float64\n",
      " 8   class   1484 non-null   object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 115.9+ KB\n",
      "None\n",
      "\n",
      "Basic Statistics:\n",
      "               mcg          gvh          alm          mit          erl  \\\n",
      "count  1484.000000  1484.000000  1484.000000  1484.000000  1484.000000   \n",
      "mean      0.500121     0.499933     0.500034     0.261186     0.504717   \n",
      "std       0.137299     0.123924     0.086670     0.137098     0.048351   \n",
      "min       0.110000     0.130000     0.210000     0.000000     0.500000   \n",
      "25%       0.410000     0.420000     0.460000     0.170000     0.500000   \n",
      "50%       0.490000     0.490000     0.510000     0.220000     0.500000   \n",
      "75%       0.580000     0.570000     0.550000     0.320000     0.500000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "               pox          vac          nuc  \n",
      "count  1484.000000  1484.000000  1484.000000  \n",
      "mean      0.007500     0.499885     0.276199  \n",
      "std       0.075683     0.057797     0.106491  \n",
      "min       0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.480000     0.220000  \n",
      "50%       0.000000     0.510000     0.220000  \n",
      "75%       0.000000     0.530000     0.300000  \n",
      "max       0.830000     0.730000     1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load the raw data\n",
    "print(\"1. Loading Yeast Dataset...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Load the raw data\n",
    "data = load_yeast_data()\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns)}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 20) (4084700134.py, line 20)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m'mcg': 'McGeoch's method for signal sequence recognition',\u001b[39m\n                                                            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 20)\n"
     ]
    }
   ],
   "source": [
    "# Data Structure Analysis\n",
    "print(\"2. Data Structure Analysis\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {data.duplicated().sum()}\")\n",
    "\n",
    "# Feature names and descriptions\n",
    "feature_names = ['mcg', 'gvh', 'alm', 'mit', 'erl', 'pox', 'vac', 'nuc']\n",
    "feature_descriptions = {\n",
    "    'mcg': 'McGeoch\\'s method for signal sequence recognition',\n",
    "    'gvh': 'von Heijne\\'s method for signal sequence recognition',\n",
    "    'alm': 'Score of the ALOM membrane spanning region prediction program',\n",
    "    'mit': 'Score of discriminant analysis of the amino acid content of the N-terminal region (20 residues long) of mitochondrial and non-mitochondrial proteins',\n",
    "    'erl': 'Presence of \"HDEL\" substring (thought to act as a signal for retention in the endoplasmic reticulum lumen)',\n",
    "    'pox': 'Peroxisomal targeting signal in the C-terminus',\n",
    "    'vac': 'Score of discriminant analysis of the amino acid content of vacuolar and extracellular proteins',\n",
    "    'nuc': 'Score of discriminant analysis of nuclear localization signals of nuclear and non-nuclear proteins'\n",
    "}\n",
    "\n",
    "print(\"\\nFeature Descriptions:\")\n",
    "for feature, desc in feature_descriptions.items():\n",
    "    print(f\"{feature}: {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution Analysis\n",
    "print(\"3. Class Distribution Analysis\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Get class distribution\n",
    "class_counts = data['class'].value_counts()\n",
    "print(\"Class distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "print(\"\\nClass percentages:\")\n",
    "class_percentages = data['class'].value_counts(normalize=True) * 100\n",
    "print(class_percentages.round(2))\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Bar plot\n",
    "plt.subplot(1, 2, 1)\n",
    "class_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Class Distribution', fontsize=14)\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Class Distribution (Percentage)', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Class imbalance analysis\n",
    "print(\"\\nClass Imbalance Analysis:\")\n",
    "max_count = class_counts.max()\n",
    "min_count = class_counts.min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "print(f\"Most frequent class: {class_counts.idxmax()} ({max_count} samples)\")\n",
    "print(f\"Least frequent class: {class_counts.idxmin()} ({min_count} samples)\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Analysis\n",
    "print(\"4. Feature Analysis\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Separate features and target\n",
    "X = data[feature_names]\n",
    "y = data['class']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "\n",
    "# Feature statistics\n",
    "print(\"\\nFeature Statistics:\")\n",
    "feature_stats = X.describe()\n",
    "print(feature_stats)\n",
    "\n",
    "# Check for outliers using IQR method\n",
    "print(\"\\nOutlier Analysis (IQR method):\")\n",
    "for feature in feature_names:\n",
    "    Q1 = X[feature].quantile(0.25)\n",
    "    Q3 = X[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = X[(X[feature] < lower_bound) | (X[feature] > upper_bound)]\n",
    "    print(f\"{feature}: {len(outliers)} outliers ({len(outliers)/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Distributions\n",
    "print(\"5. Feature Distributions\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Create distribution plots for all features\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Histogram\n",
    "    ax.hist(X[feature], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax.set_title(f'{feature} Distribution', fontsize=12)\n",
    "    ax.set_xlabel(feature, fontsize=10)\n",
    "    ax.set_ylabel('Frequency', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Feature Distributions', fontsize=16, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Box plots for outlier detection\n",
    "plt.figure(figsize=(15, 8))\n",
    "X.boxplot(figsize=(15, 8))\n",
    "plt.title('Feature Box Plots - Outlier Detection', fontsize=16)\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Values', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "print(\"6. Correlation Analysis\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "print(\"Feature Correlation Matrix:\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated features\n",
    "print(\"\\nHighly Correlated Features (|r| > 0.7):\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], corr_val))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    for feat1, feat2, corr in high_corr_pairs:\n",
    "        print(f\"{feat1} - {feat2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"No highly correlated features found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-Feature Relationships\n",
    "print(\"7. Class-Feature Relationships\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Create box plots for each feature by class\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Create box plot\n",
    "    data.boxplot(column=feature, by='class', ax=ax)\n",
    "    ax.set_title(f'{feature} by Class', fontsize=12)\n",
    "    ax.set_xlabel('Class', fontsize=10)\n",
    "    ax.set_ylabel(feature, fontsize=10)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Feature Distributions by Class', fontsize=16, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean values by class\n",
    "print(\"\\nMean Feature Values by Class:\")\n",
    "class_means = data.groupby('class')[feature_names].mean()\n",
    "print(class_means.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Preview\n",
    "print(\"8. Data Preprocessing Preview\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"Original classes: {le.classes_}\")\n",
    "print(f\"Encoded classes: {np.unique(y_encoded)}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Train set class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test set class distribution: {np.bincount(y_test)}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nScaled train set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test set shape: {X_test_scaled.shape}\")\n",
    "print(f\"Scaled train set mean: {X_train_scaled.mean(axis=0).round(3)}\")\n",
    "print(f\"Scaled train set std: {X_train_scaled.std(axis=0).round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and Insights\n",
    "print(\"9. Summary and Insights\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "print(\"üìä Dataset Summary:\")\n",
    "print(f\"- Total samples: {len(data)}\")\n",
    "print(f\"- Features: {len(feature_names)}\")\n",
    "print(f\"- Classes: {len(data['class'].unique())}\")\n",
    "print(f\"- Missing values: {data.isnull().sum().sum()}\")\n",
    "print(f\"- Duplicate rows: {data.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\nüìà Key Insights:\")\n",
    "print(f\"- Most frequent class: {class_counts.idxmax()} ({class_counts.max()} samples)\")\n",
    "print(f\"- Least frequent class: {class_counts.idxmin()} ({class_counts.min()} samples)\")\n",
    "print(f\"- Class imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "print(f\"- Feature correlation range: {correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].min():.3f} to {correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].max():.3f}\")\n",
    "\n",
    "print(\"\\nüéØ Recommendations for ML:\")\n",
    "print(\"- Handle class imbalance (consider SMOTE or class weights)\")\n",
    "print(\"- Feature scaling is necessary (already applied)\")\n",
    "print(\"- Consider feature selection based on correlation analysis\")\n",
    "print(\"- Use stratified sampling for train/test split\")\n",
    "print(\"- Consider ensemble methods for better performance\")\n",
    "\n",
    "print(\"\\n‚úÖ EDA Complete! Ready for machine learning analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
