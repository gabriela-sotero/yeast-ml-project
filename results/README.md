# 📊 Results Directory

This directory contains all the outputs from the machine learning analysis pipeline.

## 📁 Structure

```
results/
├── figures/                # Generated visualizations
│   ├── exploratory/       # Exploratory data analysis plots
│   ├── decision_tree/     # Decision Tree specific plots
│   ├── naive_bayes/       # Naive Bayes specific plots
│   ├── logistic_regression/ # Logistic Regression plots
│   ├── knn/               # k-NN specific plots
│   ├── random_forest/     # Random Forest specific plots
│   └── comparison/        # Model comparison plots
├── metrics/               # Performance metrics and reports
│   ├── all_models.csv     # Summary of all model performances
│   └── *_report.txt       # Detailed reports for each model
└── models/                # Trained model files
    ├── *.pkl              # Pickled trained models
    ├── scaler.pkl         # Feature scaler
    └── label_encoder.npy   # Label encoder
```

## 🎯 Key Results

### Best Performing Model: **Random Forest**
- **Accuracy**: 62.3%
- **Precision**: 61.1%
- **Recall**: 62.3%
- **F1-Score**: 61.2%
- **ROC-AUC**: 85.4%

### Model Performance Ranking:
1. **Random Forest** - 62.3% accuracy
2. **k-NN** - 61.2% accuracy
3. **Logistic Regression** - 58.3% accuracy
4. **Decision Tree** - 56.1% accuracy
5. **Naive Bayes** - 12.1% accuracy

## 📈 Generated Visualizations

- **Class Distribution**: Shows the imbalance in the dataset
- **Feature Distributions**: Histograms of all 8 features
- **Correlation Matrix**: Feature relationships
- **Confusion Matrices**: Per-model classification results
- **Learning Curves**: Model performance vs training size
- **Model Comparison**: Side-by-side performance metrics

## 🤖 Trained Models

All models are saved as pickle files and can be loaded for predictions:

```python
import joblib

# Load the best model
model = joblib.load('results/models/random_forest.pkl')

# Load the scaler
scaler = joblib.load('results/models/scaler.pkl')

# Make predictions
predictions = model.predict(scaled_data)
```

## 📊 Metrics Files

- **`all_models.csv`**: CSV file with all model performance metrics
- **`*_report.txt`**: Detailed classification reports for each model
- **Confusion matrices**: Per-class performance breakdown

## 🔄 Regenerating Results

To regenerate all results, run:
```python
from src.run_all import run_complete_pipeline
results, models = run_complete_pipeline()
```

## 📝 Notes

- All files are automatically generated by the pipeline
- Models are saved in pickle format for easy loading
- Visualizations are saved as high-resolution PNG files
- Results are reproducible with the same random seed (42)
