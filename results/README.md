# ğŸ“Š Results Directory

This directory contains all the outputs from the machine learning analysis pipeline.

## ğŸ“ Structure

```
results/
â”œâ”€â”€ figures/                # Generated visualizations
â”‚   â”œâ”€â”€ exploratory/       # Exploratory data analysis plots
â”‚   â”œâ”€â”€ decision_tree/     # Decision Tree specific plots
â”‚   â”œâ”€â”€ naive_bayes/       # Naive Bayes specific plots
â”‚   â”œâ”€â”€ logistic_regression/ # Logistic Regression plots
â”‚   â”œâ”€â”€ knn/               # k-NN specific plots
â”‚   â”œâ”€â”€ random_forest/     # Random Forest specific plots
â”‚   â””â”€â”€ comparison/        # Model comparison plots
â”œâ”€â”€ metrics/               # Performance metrics and reports
â”‚   â”œâ”€â”€ all_models.csv     # Summary of all model performances
â”‚   â””â”€â”€ *_report.txt       # Detailed reports for each model
â””â”€â”€ models/                # Trained model files
    â”œâ”€â”€ *.pkl              # Pickled trained models
    â”œâ”€â”€ scaler.pkl         # Feature scaler
    â””â”€â”€ label_encoder.npy   # Label encoder
```

## ğŸ¯ Key Results

### Best Performing Model: **Random Forest**
- **Accuracy**: 62.3%
- **Precision**: 61.1%
- **Recall**: 62.3%
- **F1-Score**: 61.2%
- **ROC-AUC**: 85.4%

### Model Performance Ranking:
1. **Random Forest** - 62.3% accuracy
2. **k-NN** - 61.2% accuracy
3. **Logistic Regression** - 58.3% accuracy
4. **Decision Tree** - 56.1% accuracy
5. **Naive Bayes** - 12.1% accuracy

## ğŸ“ˆ Generated Visualizations

- **Class Distribution**: Shows the imbalance in the dataset
- **Feature Distributions**: Histograms of all 8 features
- **Correlation Matrix**: Feature relationships
- **Confusion Matrices**: Per-model classification results
- **Learning Curves**: Model performance vs training size
- **Model Comparison**: Side-by-side performance metrics

## ğŸ¤– Trained Models

All models are saved as pickle files and can be loaded for predictions:

```python
import joblib

# Load the best model
model = joblib.load('results/models/random_forest.pkl')

# Load the scaler
scaler = joblib.load('results/models/scaler.pkl')

# Make predictions
predictions = model.predict(scaled_data)
```

## ğŸ“Š Metrics Files

- **`all_models.csv`**: CSV file with all model performance metrics
- **`*_report.txt`**: Detailed classification reports for each model
- **Confusion matrices**: Per-class performance breakdown

## ğŸ”„ Regenerating Results

To regenerate all results, run:
```python
from src.run_all import run_complete_pipeline
results, models = run_complete_pipeline()
```

## ğŸ“ Notes

- All files are automatically generated by the pipeline
- Models are saved in pickle format for easy loading
- Visualizations are saved as high-resolution PNG files
- Results are reproducible with the same random seed (42)
