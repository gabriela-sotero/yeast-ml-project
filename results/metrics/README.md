# üìä Metrics Directory

This directory contains all performance metrics and evaluation reports from the machine learning analysis.

## üìÅ Structure

```
metrics/
‚îú‚îÄ‚îÄ all_models.csv                    # Summary of all model performances
‚îú‚îÄ‚îÄ decision_tree_report.txt         # Detailed Decision Tree report
‚îú‚îÄ‚îÄ naive_bayes_report.txt           # Detailed Naive Bayes report
‚îú‚îÄ‚îÄ logistic_regression_report.txt   # Detailed Logistic Regression report
‚îú‚îÄ‚îÄ knn_report.txt                   # Detailed k-NN report
‚îî‚îÄ‚îÄ random_forest_report.txt         # Detailed Random Forest report
```

## üìà Performance Summary

### **Overall Results** (`all_models.csv`)
| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| **Random Forest** | **62.3%** | **61.1%** | **62.3%** | **61.2%** | **85.4%** |
| **k-NN** | **61.2%** | **60.6%** | **61.2%** | **60.0%** | **83.9%** |
| **Logistic Regression** | **58.3%** | **58.5%** | **58.3%** | **56.8%** | **83.3%** |
| **Decision Tree** | **56.1%** | **55.0%** | **56.1%** | **54.1%** | **76.7%** |
| **Naive Bayes** | **12.1%** | **36.5%** | **12.1%** | **13.4%** | **73.2%** |

### **Key Insights**:
- **Best Model**: Random Forest with 62.3% accuracy
- **Worst Model**: Naive Bayes with 12.1% accuracy
- **Close Competition**: k-NN and Random Forest perform similarly
- **ROC-AUC**: All models show good discrimination ability (>70%)

## üìÑ Detailed Reports

Each model has a detailed text report containing:

### **Classification Report**:
- **Precision**: Per-class precision scores
- **Recall**: Per-class recall scores
- **F1-Score**: Per-class F1-scores
- **Support**: Number of samples per class
- **Macro/Weighted Averages**: Overall performance metrics

### **Confusion Matrix**:
- **True vs Predicted**: Classification results
- **Per-Class Performance**: Detailed breakdown
- **Error Analysis**: Common misclassifications

## üîç Model-Specific Analysis

### **Random Forest** (Best Model):
- **Strengths**: High accuracy, good generalization
- **Weaknesses**: Some overfitting to majority classes
- **Key Features**: Feature importance analysis available
- **Hyperparameters**: 300 trees, max_depth=20

### **k-NN** (Second Best):
- **Strengths**: Simple, interpretable, good performance
- **Weaknesses**: Sensitive to feature scaling
- **Key Features**: Distance-based classification
- **Hyperparameters**: k=11, distance weighting

### **Logistic Regression** (Third):
- **Strengths**: Linear decision boundary, fast
- **Weaknesses**: Limited by linear assumptions
- **Key Features**: Coefficient analysis available
- **Hyperparameters**: C=1.0, L2 regularization

### **Decision Tree** (Fourth):
- **Strengths**: Interpretable, feature importance
- **Weaknesses**: Prone to overfitting
- **Key Features**: Tree structure visualization
- **Hyperparameters**: max_depth=20, min_samples_split=10

### **Naive Bayes** (Worst):
- **Strengths**: Fast, probabilistic
- **Weaknesses**: Independence assumption violated
- **Key Features**: Class conditional probabilities
- **Issues**: Poor performance due to feature correlations

## üìä Evaluation Methodology

### **Cross-Validation**:
- **Folds**: 5-fold cross-validation
- **Stratification**: Maintains class distribution
- **Scoring**: Accuracy, precision, recall, F1-score

### **Train/Test Split**:
- **Training**: 70% of data (1,038 samples)
- **Testing**: 30% of data (446 samples)
- **Stratification**: Preserves class proportions
- **Random State**: 42 for reproducibility

### **Feature Scaling**:
- **Method**: StandardScaler (mean=0, std=1)
- **Applied to**: k-NN, Logistic Regression
- **Not Applied**: Decision Tree, Random Forest, Naive Bayes

## üîÑ Regenerating Metrics

To regenerate all metrics:
```python
from src.run_all import run_complete_pipeline
results, models = run_complete_pipeline()
```

## üìù Notes

- All metrics are automatically generated by the pipeline
- Results are reproducible with random seed 42
- CSV format allows easy analysis in Excel/Python
- Text reports provide detailed per-class analysis
- Metrics follow scikit-learn conventions

