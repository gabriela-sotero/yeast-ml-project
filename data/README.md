# 📊 Data Directory

This directory contains all the data files for the Yeast dataset machine learning project.

## 📁 Structure

```
data/
├── raw/                    # Original dataset files
│   ├── yeast.data         # Main dataset (1,484 samples, 8 features)
│   └── yeast.names        # Dataset metadata and descriptions
└── processed/              # Preprocessed data files
    ├── X_train.csv        # Training features (1,038 samples)
    ├── X_test.csv         # Test features (446 samples)
    ├── y_train.csv        # Training labels (1,038 samples)
    └── y_test.csv         # Test labels (446 samples)
```

## 🧬 Dataset Information

- **Source**: UCI Machine Learning Repository
- **Task**: Multi-class classification (10 classes)
- **Samples**: 1,484 total
- **Features**: 8 numerical features
- **Classes**: 10 yeast protein localization sites

### Features:
- `mcg` - McGeoch's method for signal sequence recognition
- `gvh` - von Heijne's method for signal sequence recognition
- `alm` - Score of the ALOM membrane spanning region prediction program
- `mit` - Score of discriminant analysis of the amino acid content of the N-terminal region
- `erl` - Presence of "HDEL" substring (thought to act as a signal for retention in the endoplasmic reticulum)
- `pox` - Peroxisomal targeting signal in the C-terminus
- `vac` - Score of discriminant analysis of the amino acid content of vacuolar proteins
- `nuc` - Score of discriminant analysis of nuclear localization signals of nuclear and non-nuclear proteins

### Classes:
- `MIT` - Mitochondrial
- `NUC` - Nuclear
- `CYT` - Cytoplasmic
- `ME1` - Membrane protein type I
- `EXC` - Extracellular
- `ME2` - Membrane protein type II
- `ME3` - Membrane protein type III
- `VAC` - Vacuolar
- `POX` - Peroxisomal
- `ERL` - Endoplasmic reticulum lumen

## 📈 Data Processing

The raw data is automatically processed by the pipeline:
1. **Loading**: Raw data is loaded from `yeast.data`
2. **Preprocessing**: Features are separated from labels, labels are encoded
3. **Splitting**: Data is split into 70% training, 30% testing
4. **Scaling**: Features are standardized using StandardScaler
5. **Saving**: Processed data is saved to CSV files

## 🔄 Usage

```python
from src.data_loader import load_processed_data

# Load preprocessed data
X_train, X_test, y_train, y_test = load_processed_data()
```

## 📝 Notes

- All data files are automatically generated by the pipeline
- The processed data includes feature scaling and label encoding
- Original class names are preserved in the label encoder

